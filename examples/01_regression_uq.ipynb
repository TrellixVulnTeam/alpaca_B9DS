{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Uncertainty estimation for regression\n",
    "We would demonstrate how to estimate the uncertainty for a regression task. In this case we treat uncertainty as a standard deviation for test data points.\n",
    "As an example dataset we take the kinemtic movement data from UCI database and would estimate the uncertainty prediction with log likelihood metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "from alpaca.ue import MCDUE\n",
    "from alpaca.utils.datasets.builder import build_dataset\n",
    "from alpaca.utils.ue_metrics import ndcg, uq_ll\n",
    "from alpaca.ue.masks import BasicBernoulliMask, DecorrelationMask, LeverageScoreMask\n",
    "from alpaca.utils import model_builder\n",
    "import alpaca.nn as ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "The alpaca library has a few regression dataset provided (these datasets often used in the related scientific papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset('kin8nm', val_split=1_000)\n",
    "x_train, y_train = dataset.dataset('train')\n",
    "x_val, y_val = dataset.dataset('val')\n",
    "x_train.shape, y_val.shape\n",
    "train_ds = TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "val_ds = TensorDataset(torch.FloatTensor(x_val), torch.FloatTensor(y_val))\n",
    "train_loader = DataLoader(train_ds, batch_size=512)\n",
    "val_loader = DataLoader(val_ds, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the simple model\n",
    "We'll replace common nn.Dropout layer with ann.Dropout from alpaca.\n",
    "Alpaca version allow to switch on the dropout during inference without worrying other \"training\" layers, like batch norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, base_size=64, dropout_rate=0., dropout_mask=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 4*base_size),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(4*base_size, 2*base_size),\n",
    "            ann.Dropout(dropout_rate, dropout_mask),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(2*base_size, 1*base_size),\n",
    "            ann.Dropout(dropout_rate, dropout_mask),\n",
    "            nn.CELU(),\n",
    "\n",
    "            nn.Linear(base_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = MLP(input_size=8, dropout_rate=0.1, dropout_mask=BasicBernoulliMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss on last batch 0.000422369601437822\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model.train()\n",
    "for epochs in range(100):\n",
    "    for x_batch, y_batch in train_loader: # Train for one epoch\n",
    "        predictions = model(x_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print('Train loss on last batch', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9217043442551243\n"
     ]
    }
   ],
   "source": [
    "# Check model effectiveness \n",
    "model.eval()\n",
    "x_batch, y_batch = next(iter(val_loader))\n",
    "predictions = model(x_batch).detach().cpu().numpy()\n",
    "print('R2:', r2_score(predictions, y_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate uncertainty\n",
    "We compare the log likelihood for constant prediction and monte-carlo uncertainty estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score for const std is  0.27723035\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "const_std = np.std(y_val)\n",
    "errors = np.abs(predictions - y_batch.reshape((-1)).numpy())\n",
    "score = uq_ll(errors, np.ones_like(errors) * const_std)\n",
    "print(\"Quality score for const std is \", score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "estimator = MCDUE(model, nn_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uncertainty estimation with MCDUE_regression approach: 100%|██████████| 100/100 [00:00<00:00, 2998.07it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions, estimations = estimator(x_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score for monte-carlo dropout is  0.37827393\n"
     ]
    }
   ],
   "source": [
    "errors = np.abs(predictions - y_batch.reshape((-1)).numpy())\n",
    "score = uq_ll(np.array(errors), predictions)\n",
    "print(\"Quality score for monte-carlo dropout is \", score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}